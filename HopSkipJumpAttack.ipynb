{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://drive.google.com/uc?id=13Un3zyjk1feC8ryZvIXe-kyvOIf5FP5h\">\n"
      ],
      "metadata": {
        "id": "ZH4dlTNm7ieO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6ulqAhuSlqU"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HopSkipJumpAttack algorithm"
      ],
      "metadata": {
        "id": "Ita_rLin_86v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm, trange\n",
        "def hsja(predict, \n",
        "\tsample, \n",
        "\tclip_max = 1, \n",
        "\tclip_min = 0, \n",
        "\tconstraint = 'l2', \n",
        "\tnum_iterations = 40, \n",
        "\tgamma = 1.0, \n",
        "\ttarget_label = None, \n",
        "\ttarget_image = None, \n",
        "\tstepsize_search = 'geometric_progression', \n",
        "\tmax_num_evals = 1e4,\n",
        "\tinit_num_evals = 100,\n",
        "\tverbose = False):\n",
        "\t\"\"\"\n",
        "\tMain algorithm for HopSkipJumpAttack.\n",
        "\tInputs:\n",
        "\tmodel: the object that has predict method. \n",
        "\tpredict outputs probability scores.\n",
        "\tclip_max: upper bound of the image.\n",
        "\tclip_min: lower bound of the image.\n",
        "\tconstraint: choose between [l2, linf].\n",
        "\tnum_iterations: number of iterations.\n",
        "\tgamma: used to set binary search threshold theta. The binary search \n",
        "\tthreshold theta is gamma / d^{3/2} for l2 attack and gamma / d^2 for \n",
        "\tlinf attack.\n",
        "\ttarget_label: integer or None for nontargeted attack.\n",
        "\ttarget_image: an array with the same size as sample, or None. \n",
        "\tstepsize_search: choose between 'geometric_progression', 'grid_search'.\n",
        "\tmax_num_evals: maximum number of evaluations for estimating gradient (for each iteration). \n",
        "\tThis is not the total number of model evaluations for the entire algorithm, you need to \n",
        "\tset a counter of model evaluations by yourself to get that. To increase the total number \n",
        "\tof model evaluations, set a larger num_iterations. \n",
        "\tinit_num_evals: initial number of evaluations for estimating gradient.\n",
        "\tOutput:\n",
        "\tperturbed image.\n",
        "\t\n",
        "\t\"\"\"\n",
        "\n",
        "\t# Set parameters\n",
        "\toriginal_label = np.argmax(predict(sample)) \n",
        "  \n",
        "\tparams = {'clip_max': clip_max, 'clip_min': clip_min, \n",
        "\t\t\t\t'shape': sample.shape,\n",
        "\t\t\t\t'original_label': original_label, \n",
        "\t\t\t\t'target_label': target_label,\n",
        "\t\t\t\t'target_image': target_image, \n",
        "\t\t\t\t'constraint': constraint,\n",
        "\t\t\t\t'num_iterations': num_iterations, \n",
        "\t\t\t\t'gamma': gamma, \n",
        "\t\t\t\t'd': int(np.prod(sample.shape)), \n",
        "\t\t\t\t'stepsize_search': stepsize_search,\n",
        "\t\t\t\t'max_num_evals': max_num_evals,\n",
        "\t\t\t\t'init_num_evals': init_num_evals,\n",
        "\t\t\t\t'verbose': verbose,\n",
        "\t\t\t\t}\n",
        "\t# Set binary search threshold.\n",
        "\tif params['constraint'] == 'l2':\n",
        "\t\tparams['theta'] = params['gamma'] / (np.sqrt(params['d']) * params['d'])\n",
        "\telse:\n",
        "\t\tparams['theta'] = params['gamma'] / (params['d'] ** 2)\n",
        "\t\t\n",
        "\t# Initialize.\n",
        "\t                                      \n",
        "\tperturbed = initialize(predict, sample, params)\n",
        "\t                           \n",
        "\t\n",
        "\n",
        "\t# Project the initialization to the boundary.\n",
        "\t                           \n",
        "\tperturbed, dist_post_update = binary_search_batch(sample, \n",
        "\t\tnp.expand_dims(perturbed, 0), \n",
        "\t\tpredict, \n",
        "\t\tparams)\n",
        "\t                           \n",
        "\t\n",
        "\tdist = compute_distance(perturbed, sample, constraint)\n",
        "\t                           \n",
        "\n",
        "\tfor j in trange(params['num_iterations'], desc=\"HopSkipJumpattack - iterations\", disable=True):\n",
        "\t\tparams['cur_iter'] = j + 1\n",
        "\n",
        "\t\t# Choose delta.\n",
        "\t\t                           \n",
        "\t\tdelta = select_delta(params, dist_post_update)\n",
        "\t\t                           \n",
        "\n",
        "\t\t# Choose number of evaluations.\n",
        "\t\tnum_evals = int(params['init_num_evals'] * np.sqrt(j+1))\n",
        "\t\tnum_evals = int(min([num_evals, params['max_num_evals']]))\n",
        "\n",
        "\t\t# approximate gradient.\n",
        "\t\t                           \n",
        "\t\tgradf = approximate_gradient(predict, perturbed, num_evals, \n",
        "\t\t\tdelta, params)\n",
        "\t\t                           \n",
        "\t\n",
        "\t\tif params['constraint'] == 'linf':\n",
        "\t\t\tupdate = np.sign(gradf)\n",
        "\t\telse:\n",
        "\t\t\tupdate = gradf\n",
        "\n",
        "\t\t# search step size.\n",
        "\t\tif params['stepsize_search'] == 'geometric_progression':\n",
        "\t\t\t# find step size.\n",
        "\t\t\t                           \t\t\t\t\n",
        "\t\t\tepsilon = geometric_progression_for_stepsize(perturbed, \n",
        "\t\t\t\tupdate, dist, predict, params)\n",
        "\t\t\t                           \t\t\n",
        "\t\t\t# Update the sample. \n",
        "\t\t\tperturbed = clip_image(perturbed + epsilon * update, \n",
        "\t\t\t\tclip_min, clip_max)\n",
        "\t\t\t                           \t\t\n",
        "\t\t\t# Binary search to return to the boundary. \n",
        "\t\t\tperturbed, dist_post_update = binary_search_batch(sample, \n",
        "\t\t\t\tperturbed[None], predict, params)\n",
        "\n",
        "\t\telif params['stepsize_search'] == 'grid_search':\n",
        "\t\t\t# Grid search for stepsize.\n",
        "\t\t\tepsilons = np.logspace(-4, 0, num=20, endpoint = True) * dist\n",
        "\t\t\tepsilons_shape = [20] + len(params['shape']) * [1]\n",
        "\t\t\tperturbeds = perturbed + epsilons.reshape(epsilons_shape) * update\n",
        "\t\t\tperturbeds = clip_image(perturbeds, params['clip_min'], params['clip_max'])\n",
        "\t\t\tidx_perturbed = decision_function(predict, perturbeds, params)\n",
        "\n",
        "\t\t\tif np.sum(idx_perturbed) > 0:\n",
        "\t\t\t\t# Select the perturbation that yields the minimum distance # after binary search.\n",
        "\t\t\t\tperturbed, dist_post_update = binary_search_batch(sample, \n",
        "\t\t\t\t\tperturbeds[idx_perturbed], predict, params)\n",
        "\n",
        "\t\t# compute new distance.\n",
        "\t\tdist = compute_distance(perturbed, sample, constraint)\n",
        "\t\tif verbose:\n",
        "\t\t\tprint('iteration: {:d}, {:s} distance {:.4E}'.format(j+1, constraint, dist))\n",
        "\n",
        "\treturn perturbed\n"
      ],
      "metadata": {
        "id": "vOG-ceEWTSfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc6b24b-3d1b-43ff-af29-a15045e86885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decision_function(predict, images, params):\n",
        "\t\"\"\"\n",
        "\tDecision function output 1 on the desired side of the boundary,\n",
        "\t0 otherwise.\n",
        "\t\"\"\"\n",
        "\t                           \n",
        "\timages = clip_image(images, params['clip_min'], params['clip_max'])\n",
        "\t                           \n",
        "\tprob = predict(images)\n",
        "\n",
        "\tif params['target_label'] is None:\n",
        "\t\t                           \n",
        "\t\treturn np.argmax(prob) != params['original_label'] \n",
        "\n",
        "\telse:\n",
        "\n",
        "\t\treturn np.argmax(prob) == params['target_label']\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jdDcBS6LXr6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_image(image, clip_min, clip_max):\n",
        "\t# Clip an image, or an image batch, with upper and lower threshold.\n",
        "\treturn np.minimum(np.maximum(clip_min, image), clip_max) \n"
      ],
      "metadata": {
        "id": "sB2aSQZsX-7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_distance(x_ori, x_pert, constraint = 'l2'):\n",
        "\t# Compute the distance between two images.\n",
        "\tif constraint == 'l2':\n",
        "\t\treturn np.linalg.norm(x_ori - x_pert)\n",
        "\telif constraint == 'linf':\n",
        "\t\treturn np.max(abs(x_ori - x_pert))"
      ],
      "metadata": {
        "id": "ejnCP6KoYEjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def approximate_gradient(predict, sample, num_evals, delta, params):\n",
        "\t                           \n",
        "\tclip_max, clip_min = params['clip_max'], params['clip_min']\n",
        "\t                           \n",
        "\t# Generate random vectors.\n",
        "\tnoise_shape =  list(params['shape'])\n",
        "\t                           \n",
        "\tif params['constraint'] == 'l2':\n",
        "\t\trv = np.random.randn(*noise_shape)\n",
        "\t\t                           \n",
        "\telif params['constraint'] == 'linf':\n",
        "\t\trv = np.random.uniform(low = -1, high = 1, size = noise_shape)\n",
        "\t\t                           \n",
        "\n",
        "\trv = rv / np.sqrt(np.sum(rv ** 2, axis = (0, 1), keepdims = True))\n",
        "\t                           \n",
        "\tperturbed = sample + delta * rv\n",
        "\t                           \n",
        "\tperturbed = clip_image(perturbed, clip_min, clip_max)\n",
        "\t                           \n",
        "\trv = (perturbed - sample) / delta\n",
        "\t                           \n",
        "\n",
        "\t# query the model.\n",
        "\tdecisions = decision_function(predict, perturbed, params)\n",
        "\t                           \n",
        "\t#decision_shape = [len(decisions)] + [1] * len(params['shape'])\n",
        "\tdecision_shape = [1] + [1] * len(params['shape'])\n",
        "\t                           \n",
        "\tfval = 2 * decisions.astype(float).reshape(decision_shape) - 1.0\n",
        "\t                           \n",
        "\n",
        "\t# Baseline subtraction (when fval differs)\n",
        "\tif np.mean(fval) == 1.0: # label changes.\n",
        "\t\t                            \n",
        "\t\tgradf = np.mean(rv, axis = 0)\n",
        "\telif np.mean(fval) == -1.0: # label not change.\n",
        "\t\tgradf = - np.mean(rv, axis = 0)\n",
        "\t\t                            \n",
        "\telse:\n",
        "\t\tfval -= np.mean(fval)\n",
        "\t\tgradf = np.mean(fval * rv, axis = 0) \n",
        "\t\t                            \n",
        "\n",
        "\t# Get the gradient direction.\n",
        "\tgradf = gradf / np.linalg.norm(gradf)\n",
        "\t                           \n",
        "\n",
        "\treturn gradf\n"
      ],
      "metadata": {
        "id": "4iQBX3OxYMr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def project(original_image, perturbed_images, alphas, params):\n",
        "\talphas_shape = [len(alphas)] + [1] * len(params['shape'])\n",
        "\talphas = alphas.reshape(alphas_shape)\n",
        "\tif params['constraint'] == 'l2':\n",
        "\t\treturn (1-alphas) * original_image + alphas * perturbed_images\n",
        "\telif params['constraint'] == 'linf':\n",
        "\t\tout_images = clip_image(\n",
        "\t\t\tperturbed_images, \n",
        "\t\t\toriginal_image - alphas, \n",
        "\t\t\toriginal_image + alphas\n",
        "\t\t\t)\n",
        "\t\treturn out_images"
      ],
      "metadata": {
        "id": "IaCkBCiPYdBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def binary_search_batch(original_image, perturbed_images, predict, params):\n",
        "\t\"\"\" Binary search to approach the boundar. \"\"\"\n",
        "\n",
        "\t# Compute distance between each of perturbed image and original image.\n",
        "\tdists_post_update = np.array([\n",
        "\t\t\tcompute_distance(\n",
        "\t\t\t\toriginal_image, \n",
        "\t\t\t\tperturbed_image, \n",
        "\t\t\t\tparams['constraint']\n",
        "\t\t\t) \n",
        "\t\t\tfor perturbed_image in perturbed_images])\n",
        "\n",
        "\t# Choose upper thresholds in binary searchs based on constraint.\n",
        "\tif params['constraint'] == 'linf':\n",
        "\t\thighs = dists_post_update\n",
        "\t\t# Stopping criteria.\n",
        "\t\tthresholds = np.minimum(dists_post_update * params['theta'], params['theta'])\n",
        "\telse:\n",
        "\t\thighs = np.ones(len(perturbed_images))\n",
        "\t\tthresholds = params['theta']\n",
        "\n",
        "\tlows = np.zeros(len(perturbed_images))\n",
        "\n",
        "\t\n",
        "\n",
        "\t# Call recursive function. \n",
        "\twhile np.max((highs - lows) / thresholds) > 1:\n",
        "\t\t# projection to mids.\n",
        "\t\tmids = (highs + lows) / 2.0\n",
        "\t\tmid_images = project(original_image, perturbed_images, mids, params)\n",
        "\n",
        "\t\t# Update highs and lows based on model decisions.\n",
        "\t\tdecisions = decision_function(predict, mid_images, params)\n",
        "\t\tlows = np.where(decisions == 0, mids, lows)\n",
        "\t\thighs = np.where(decisions == 1, mids, highs)\n",
        "\n",
        "\tout_images = project(original_image, perturbed_images, highs, params)\n",
        "\n",
        "\t# Compute distance of the output image to select the best choice. \n",
        "\t# (only used when stepsize_search is grid_search.)\n",
        "\tdists = np.array([\n",
        "\t\tcompute_distance(\n",
        "\t\t\toriginal_image, \n",
        "\t\t\tout_image, \n",
        "\t\t\tparams['constraint']\n",
        "\t\t) \n",
        "\t\tfor out_image in out_images])\n",
        "\tidx = np.argmin(dists)\n",
        "\n",
        "\tdist = dists_post_update[idx]\n",
        "\tout_image = out_images[idx]\n",
        "\treturn out_image, dist"
      ],
      "metadata": {
        "id": "zQAYPccwYjFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def initialize(predict, sample, params):\n",
        "\t\"\"\" \n",
        "\tEfficient Implementation of BlendedUniformNoiseAttack in Foolbox.\n",
        "\t\"\"\"\n",
        "\tsuccess = 0\n",
        "\tnum_evals = 0\n",
        "\n",
        "\tif params['target_image'] is None:\n",
        "\t\t# Find a misclassified random noise.\n",
        "\t\twhile True:\n",
        "\t\t\trandom_noise = np.random.uniform(params['clip_min'], \n",
        "\t\t\t\tparams['clip_max'], size = params['shape'])\n",
        "\n",
        "\t\t\tsuccess = decision_function(predict,random_noise[None], params)\n",
        "\t\t\t#success = decision_function(predict,random_noise[None], params)[0]\n",
        "\t\t\tnum_evals += 1\n",
        "\t\t\tif success:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tassert num_evals < 1e4,\"Initialization failed! \"\n",
        "\t\t\t\"Use a misclassified image as `target_image`\" \n",
        "\n",
        "\n",
        "\t\t# Binary search to minimize l2 distance to original image.\n",
        "\t\tlow = 0.0\n",
        "\t\thigh = 1.0\n",
        "\t\twhile high - low > 0.001:\n",
        "\t\t\tmid = (high + low) / 2.0\n",
        "\t\t\tblended = (1 - mid) * sample + mid * random_noise \n",
        "\t\t\tsuccess = decision_function(predict, blended[None], params)\n",
        "\t\t\tif success:\n",
        "\t\t\t\thigh = mid\n",
        "\t\t\telse:\n",
        "\t\t\t\tlow = mid\n",
        "\n",
        "\t\tinitialization = (1 - high) * sample + high * random_noise \n",
        "\n",
        "\telse:\n",
        "\t\tinitialization = params['target_image']\n",
        "\treturn initialization"
      ],
      "metadata": {
        "id": "CIvv91zlYno7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def geometric_progression_for_stepsize(x, update, dist, predict, params):\n",
        "\t\"\"\"\n",
        "\tGeometric progression to search for stepsize.\n",
        "\tKeep decreasing stepsize by half until reaching \n",
        "\tthe desired side of the boundary,\n",
        "\t\"\"\"\n",
        "\tepsilon = dist / np.sqrt(params['cur_iter']) \n",
        "\n",
        "\tdef phi(epsilon):\n",
        "\t\tnew = x + epsilon * update\n",
        "\t\tsuccess = decision_function(predict, new[None], params)\n",
        "\t\treturn success\n",
        "\n",
        "\twhile not phi(epsilon):\n",
        "\t\tepsilon /= 2.0\n",
        "\n",
        "\treturn epsilon\n"
      ],
      "metadata": {
        "id": "jI9G9uJHYqkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_delta(params, dist_post_update):\n",
        "\t\"\"\" \n",
        "\tChoose the delta at the scale of distance \n",
        "\tbetween x and perturbed sample. \n",
        "\t\"\"\"\n",
        "\tif params['cur_iter'] == 1:\n",
        "\t\tdelta = 0.1 * (params['clip_max'] - params['clip_min'])\n",
        "\telse:\n",
        "\t\tif params['constraint'] == 'l2':\n",
        "\t\t\tdelta = np.sqrt(params['d']) * params['theta'] * dist_post_update\n",
        "\t\telif params['constraint'] == 'linf':\n",
        "\t\t\tdelta = params['d'] * params['theta'] * dist_post_update\t\n",
        "\n",
        "\treturn delta"
      ],
      "metadata": {
        "id": "PjO6CvaKYs7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Ce texte est au format code\n",
        "```\n",
        "\n",
        "# Loading the network ids NIDS\n",
        "## You can doawnload [model500Path]( https://drive.google.com/drive/folders/1tYagVDNPgiAgBZeBOO8eODuT0FKzpC9l?usp=sharing) and [modelPath](model500Path) and save them on Google Drive \n",
        "\n"
      ],
      "metadata": {
        "id": "ITbKzKpFbTLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import tensorflow as tf\n",
        "\n",
        "model500Path = \"hidden link\"\n",
        "modelPath = \"hidden link\"\n",
        "\n",
        "model = tf.saved_model.load(modelPath)\n",
        "model500 = tf.saved_model.load(model500Path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "WloMHp0LbVUN",
        "outputId": "b4d1da0c-92ff-4d63-8568-90c6b4112983"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-66e413bc9816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel500Path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/PFE-2021-Khettaf-Dalila-AttaquesIDS/content/LSTMNIDS500/content/LSTM-NIDS-500\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodelPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/PFE-2021-Khettaf-Dalila-AttaquesIDS/content/LSTM-NIDS\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mephemeral\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       readonly=readonly)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 125\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading attack data od NSL-KDD\n",
        "## You can download the attack file [here](https://drive.google.com/file/d/1h1Q89-l9_JC9R-XPNpxdSSwJLzT2w4QL/view?usp=sharing)\n"
      ],
      "metadata": {
        "id": "b2j0GZ0AAXFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "#xTrainPath = 'hidden link'\n",
        "#yTrainPath = 'hidden link'\n",
        "AttacksPath = 'hidden path'\n",
        "Attacks = load(AttacksPath)\n",
        "#Attacks = np.reshape(Attacks, (Attacks.shape[0], 113))\n",
        "#xTrain = load(xTrainPath, mmap_mode=None, allow_pickle=True, fix_imports=True, encoding='ASCII')\n",
        "#yTrain = load(yTrainPath)"
      ],
      "metadata": {
        "id": "U9juJZhKbgH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction function of the NIDS"
      ],
      "metadata": {
        "id": "FB63yZsBBhIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def predictx(x):\n",
        "  inp = tf.convert_to_tensor(x)\n",
        "  inp = tf.cast(inp, tf.float32)\n",
        "  #if len(inp.shape) > 3:\n",
        "    #inp = np.expand_dims(inp, 0) \n",
        "  inp = np.reshape(inp, (1, 1, 113))\n",
        "  labeling = model500(inp)\n",
        "  prediction = np.argmax(labeling)\n",
        "  oneHotEncode = [0, 0]\n",
        "  if prediction == 0:\n",
        "    oneHotEncode[0] = 1\n",
        "  else:\n",
        "    oneHotEncode[1] = 1\n",
        "  return np.array(oneHotEncode)"
      ],
      "metadata": {
        "id": "iRCb60iYbpPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AE generation with HSJA attack"
      ],
      "metadata": {
        "id": "TZ6DOjpoEzkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate an adversarial example\n",
        "# The parameters\n",
        "adv_examples = []\n",
        "predict = predictx\n",
        "#sample = xTrain[2]\n",
        "clip_max = 5\n",
        "clip_min = -5\n",
        "constraint = 'l2'\n",
        "num_iterations = 40\n",
        "gamma = 1.0\n",
        "target_label = 0\n",
        "target_image = None, \n",
        "stepsize_search = 'geometric_progression', \n",
        "max_num_evals = 1e4\n",
        "init_num_evals = 100\n",
        "for i in trange(100, desc=\"HopSkipJumpAttack - iterations\", disable=False):\n",
        "  sample = Attacks[i]\n",
        "  adv = hsja(predictx, sample, clip_max, clip_min, constraint, num_iterations, gamma, target_label, None, stepsize_search, max_num_evals, init_num_evals, False)\n",
        "  adv_examples.append(adv)"
      ],
      "metadata": {
        "id": "NcX1_jgWb1Br",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce370547-c4b5-4d56-dce0-0d030db27cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "HopSkipJumpAttack - iterations: 100%|██████████| 100/100 [01:00<00:00,  1.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the AE in Google Drive"
      ],
      "metadata": {
        "id": "xzF4FwX97rQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = \"hidden path\"\n",
        "np.save(f, adv_examples)"
      ],
      "metadata": {
        "id": "_4CqiozN8hhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attacking the NIDS"
      ],
      "metadata": {
        "id": "0cDjLRFn_u8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "success = 0\n",
        "def predict(model, x):\n",
        "  inp = tf.convert_to_tensor(x)\n",
        "  inp = tf.cast(inp, tf.float32)\n",
        "  inp = tf.reshape(inp, ( 1, 1, 113))\n",
        "  labeling = model(inp)\n",
        "  label = np.argmax(labeling)\n",
        "  \n",
        "  return label\n",
        "for i in range(100):\n",
        "  prediction = predict(model500,adv_examples[i])\n",
        "  if prediction == 0:\n",
        "    success += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "bk0xdHhA_vnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"success rate of HSJA is \", success, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OhYk2fH_y6X",
        "outputId": "2e9a0d78-2b30-4209-c3bd-bb84f5834052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "success rate of HSJA is  100 %\n"
          ]
        }
      ]
    }
  ]
}