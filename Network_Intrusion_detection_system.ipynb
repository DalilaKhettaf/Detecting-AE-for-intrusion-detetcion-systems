{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBuZlh6Ec6ul"
      },
      "source": [
        "# 1. Preprocessing of NSL-KDD dataset \n",
        "## The file KDDTrain+.txt and KDDTest+.txt can be downloaded from this [link](https://drive.google.com/drive/folders/1VozlSOkxCxDyhNF4osTUYr3JWnjT1yxM?usp=sharing)\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 Loading the dataset"
      ],
      "metadata": {
        "id": "-7-FCkGIyvwI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "66Z_KVHgFSsH"
      },
      "outputs": [],
      "source": [
        "# importing required libraries for Part 1: Data Preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# importing required libraries for normalizing data\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://drive.google.com/uc?id=172J1lUfNWg_PVgssue63ndJeZHewsRri\">\n"
      ],
      "metadata": {
        "id": "P6syk9Ehnk8-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "egpTza6BKBm0"
      },
      "outputs": [],
      "source": [
        "# Loading the data\n",
        "def Load(fileName, description = False):\n",
        "  # Manually setting up the features\n",
        "  col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty_level\"]\n",
        "  # importing dataset\n",
        "  data = pd.read_csv(fileName,header=None, names=col_names)\n",
        "  if description:\n",
        "    data.describe()\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Dataset features"
      ],
      "metadata": {
        "id": "VyklyXLBzu-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Load(\"KDDTrain+.txt\", True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "yaFzI0Od1z70",
        "outputId": "6c0381ff-6b57-4d26-99a9-b65851ce2bae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
              "0         0           tcp  ftp_data   SF        491          0     0   \n",
              "1         0           udp     other   SF        146          0     0   \n",
              "2         0           tcp   private   S0          0          0     0   \n",
              "3         0           tcp      http   SF        232       8153     0   \n",
              "4         0           tcp      http   SF        199        420     0   \n",
              "\n",
              "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
              "0               0       0    0  ...                    0.17   \n",
              "1               0       0    0  ...                    0.00   \n",
              "2               0       0    0  ...                    0.10   \n",
              "3               0       0    0  ...                    1.00   \n",
              "4               0       0    0  ...                    1.00   \n",
              "\n",
              "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
              "0                    0.03                         0.17   \n",
              "1                    0.60                         0.88   \n",
              "2                    0.05                         0.00   \n",
              "3                    0.00                         0.03   \n",
              "4                    0.00                         0.00   \n",
              "\n",
              "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
              "0                         0.00                  0.00   \n",
              "1                         0.00                  0.00   \n",
              "2                         0.00                  1.00   \n",
              "3                         0.04                  0.03   \n",
              "4                         0.00                  0.00   \n",
              "\n",
              "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
              "0                      0.00                  0.05                      0.00   \n",
              "1                      0.00                  0.00                      0.00   \n",
              "2                      1.00                  0.00                      0.00   \n",
              "3                      0.01                  0.00                      0.01   \n",
              "4                      0.00                  0.00                      0.00   \n",
              "\n",
              "     label  difficulty_level  \n",
              "0   normal                20  \n",
              "1   normal                15  \n",
              "2  neptune                19  \n",
              "3   normal                21  \n",
              "4   normal                21  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4538ae9-70b1-4aa1-98bf-7565a1e2e6b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>...</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "      <th>label</th>\n",
              "      <th>difficulty_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "      <td>491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>neptune</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>232</td>\n",
              "      <td>8153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>normal</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "      <td>199</td>\n",
              "      <td>420</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>normal</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4538ae9-70b1-4aa1-98bf-7565a1e2e6b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4538ae9-70b1-4aa1-98bf-7565a1e2e6b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4538ae9-70b1-4aa1-98bf-7565a1e2e6b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Normalisation"
      ],
      "metadata": {
        "id": "3KE7KsSXz0pj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KWIFjA81LfiG"
      },
      "outputs": [],
      "source": [
        "# Normalisation of data\n",
        "def Normalisation(data):\n",
        "  # selecting numeric attributes columns from data\n",
        "  numeric_col = data.select_dtypes(include='number').columns\n",
        "  std_scaler = StandardScaler()\n",
        "  df = data.copy()\n",
        "  for i in numeric_col:\n",
        "    arr = df[i]\n",
        "    arr = np.array(arr)\n",
        "    df[i] = std_scaler.fit_transform(arr.reshape(len(arr),1))\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Encoding the categorical data"
      ],
      "metadata": {
        "id": "tQ9hM4DTz4iP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3TxCwIAFMRxR"
      },
      "outputs": [],
      "source": [
        "# Categorial to numeric data\n",
        "def Numericalization(data, cat_col):\n",
        "  for i in cat_col:\n",
        "    # Create the One Hot Encode DataFrame\n",
        "    dum = pd.get_dummies(data[i])\n",
        "    # Insert into the dataset DataFrame by Series\n",
        "    for column_name in list(dum.columns):\n",
        "        data.insert(1, str(i)+column_name, dum[column_name])\n",
        "        data[str(i)+column_name] = data[str(i)+column_name].astype('int64')\n",
        "    # Drop the old attribute's column\n",
        "    data.drop(i, inplace=True, axis=1)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Feature selection"
      ],
      "metadata": {
        "id": "gLP8Hb-Oz_cc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T63k_O3xM0Uh"
      },
      "outputs": [],
      "source": [
        "# Feature Selection : Dropping attributes\n",
        "def featureSelect(data, colToDrop):\n",
        "  data.drop(colToDrop, axis=1, inplace=True)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 Transforming the problem into binary classification"
      ],
      "metadata": {
        "id": "8WPmSCdc0ECt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r7jGrKohJZkE"
      },
      "outputs": [],
      "source": [
        "# Replace all attack types with \"attack\"\n",
        "def replaceLabel(data):\n",
        "  # 1 intrusion, 0 normal data\n",
        "  data.loc[data[\"label\"] == \"normal\", \"label\"] = 0\n",
        "  data.loc[data[\"label\"] != 0, \"label\"] = 1\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.7 Preprocessing function"
      ],
      "metadata": {
        "id": "t6Ofv36j0LSR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fOw-4VT77ThL"
      },
      "outputs": [],
      "source": [
        "def preProcessing(fileNameTrain, fileNameTest):\n",
        "  dataTrain = Load(fileNameTrain, False)\n",
        "  dataTest = Load(fileNameTest, False)\n",
        "  data = pd.concat([dataTrain, dataTest], axis=0)\n",
        "  colToDrop = ['difficulty_level', 'num_outbound_cmds','duration', 'src_bytes', 'dst_bytes','su_attempted','num_root', 'num_file_creations', 'num_shells', 'num_access_files']\n",
        "  df = featureSelect(data, colToDrop)\n",
        "  cat_col = ['protocol_type','service','flag']\n",
        "  df = Numericalization(df, cat_col)\n",
        "  df = Normalisation(data)\n",
        "  df = replaceLabel(df)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = preProcessing('KDDTrain+.txt','KDDTest+.txt')\n",
        "#data\n"
      ],
      "metadata": {
        "id": "R63jwbnJhNmZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.8 Splitting the dataset into training and test"
      ],
      "metadata": {
        "id": "jSXn5cDb0TOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def splitData(data, trainSize):\n",
        "  df_training = data[:trainSize]    \n",
        "  df_testing = data[trainSize:]\n",
        "  return df_training, df_testing\n"
      ],
      "metadata": {
        "id": "y2Dkx2Jtl-FX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, dt = splitData(data, 126144)\n",
        "print(\"shape of training dataset \", df.shape)\n",
        "print(\"shape of inference dataset \", dt.shape)"
      ],
      "metadata": {
        "id": "S5HmE2KCmeTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ff3201-31e5-46b3-b917-ae61c20fe9c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of training dataset  (126144, 114)\n",
            "shape of inference dataset  (22373, 114)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBM0WVf2dsai"
      },
      "source": [
        "# 2. Seq2Seq LSTM NIDS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Eliminating rows of the dataset"
      ],
      "metadata": {
        "id": "ilpR7sje0oYR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "C_SfX7YjVuT3"
      },
      "outputs": [],
      "source": [
        "# Importing the packages\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from numpy import array\n",
        "from numpy import array_equal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5VtL8-LvtqNZ"
      },
      "outputs": [],
      "source": [
        "def eliminateRows(data, rowsToKeep):\n",
        "  IndexesToDrop = [i for i in range(rowsToKeep, data.shape[0],1 )]\n",
        "  data = data.drop(IndexesToDrop)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Ce texte est au format code\n",
        "```\n",
        "\n",
        "## 2.2 Getting the label Y"
      ],
      "metadata": {
        "id": "Uq0c-w1m0ys9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EEZCaEo1VZrH"
      },
      "outputs": [],
      "source": [
        "def LabelCol(data):\n",
        "  Y = []\n",
        "  Y = pd.DataFrame(Y)\n",
        "  Y['label'] = data['label'].values\n",
        "  data.drop('label', axis=1, inplace=True)\n",
        "  return data, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Transforming the dataset to an LSTM form\n",
        "\n",
        "> Bloc en retrait\n",
        "\n",
        "\n",
        "## Input data to LSTM: (sequences, time steps, features)\n",
        "## Train data shape : (126144, 1, 113) \n",
        "## Test data shape : (22272, 1, 113)"
      ],
      "metadata": {
        "id": "KxOI9YZY05TW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K4HgafhsRNsy"
      },
      "outputs": [],
      "source": [
        "# # Input data to LSTM: (sequences, time steps, features) = (656, 192, 114)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "def sequences(df, n, length, features):\n",
        "  samples = list()\n",
        "  for i in range(0,n,length):\n",
        "    sample =df[i:i+length]\n",
        "    samples.append(sample)\n",
        "  data = np.array(samples)\n",
        "  data = np.reshape(data,(len(samples) , length, features))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 One hot encoding of label Y"
      ],
      "metadata": {
        "id": "M8e544SX1DZu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EckG6oG6QODC"
      },
      "outputs": [],
      "source": [
        "# Preparing Y for seq2seq \n",
        "def prepareY(data, Y, rowsPerSeq):\n",
        "  Yencoded = to_categorical([Y], num_classes=2)\n",
        "  # Adding shifting column to Y\n",
        "  #NewY = Yencoded.reshape(data.shape[0], 2 )\n",
        "  NewY = Yencoded.reshape(data.shape[0], 2 )\n",
        "  #x2 = np.insert(NewY, 0, values=-1, axis=1)\n",
        "  #y = np.insert(NewY, 0, values=0, axis=1)\n",
        "  x2 = NewY\n",
        "  y = NewY\n",
        "  y = sequences(y, y.shape[0], rowsPerSeq, y.shape[1])\n",
        "  x2 = sequences(x2, x2.shape[0], rowsPerSeq, x2.shape[1])\n",
        "  return x2, y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Preparing data for LSTM cells"
      ],
      "metadata": {
        "id": "l85V2rZV2Ofh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C-o_wHdrW776"
      },
      "outputs": [],
      "source": [
        "# Preparing training data for seq2seq LSTM\n",
        "def dataSeq(df, rowsToKeep, rowsPerSeq):\n",
        "  # Eliminating some rows from dataset\n",
        "  df = eliminateRows(df, rowsToKeep)\n",
        "  # Creating a column of the class : Y\n",
        "  df , Y = LabelCol(df)\n",
        "  # Preparing y: predicted class and x2: shifted class labels\n",
        "  x2, y = prepareY(df, Y, rowsPerSeq)\n",
        "  x1 = sequences(df, df.shape[0], rowsPerSeq, df.shape[1])\n",
        "  return x1, x2, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E05rRYd97HX",
        "outputId": "96e5b7c3-119b-46c0-83e3-51b950cf035e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(126144, 1, 113) (126144, 1, 2) (126144, 1, 2)\n"
          ]
        }
      ],
      "source": [
        "# Preparing training data for seq2seq LSTM\n",
        "x1, x2, y = dataSeq(df, 126144, 1)\n",
        "print(x1.shape, x2.shape, y.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Test Set \n",
        "xt1, xt2, yt = dataSeq(dt, 22272, 1)\n",
        "print(xt1.shape, xt2.shape, yt.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-hrwqSAnJ--",
        "outputId": "397305e7-7805-4403-c74b-3d4459a0261b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22272, 1, 113) (22272, 1, 2) (22272, 1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Evaluation metrics\n",
        "\n",
        "> Bloc en retrait\n",
        "\n"
      ],
      "metadata": {
        "id": "zPLvdNYa2pnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Creation du modèle\n",
        "<img src = \"https://drive.google.com/uc?id=1T47KP3a0-14XzJV_NCuXPGokJ_TBqNlO\" height = \"400\" width = \"800\" > \n",
        "\n"
      ],
      "metadata": {
        "id": "5uLzvgaq2wlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oviChfscO1DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-metrics\n",
        "import keras_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIQTy_lU9gT8",
        "outputId": "e51665df-738f-445f-a404-b33c9dbc300d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-metrics\n",
            "  Downloading keras_metrics-1.1.0-py2.py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras-metrics) (2.8.0)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "n_timesteps_in = 1\n",
        "n_features = 113\n",
        "out_features = 2\n",
        "numberOfLSTMunits = 256\n",
        "\n",
        "def create_hard_coded_decoder_input_model(batch_size):\n",
        "  # The first part is encoder\n",
        "  encoder_inputs = Input(shape=(n_timesteps_in, n_features), name='encoder_inputs')\n",
        "  encoder_lstm = LSTM(numberOfLSTMunits,return_sequences=True, return_state=True,  name='encoder_lstm')\n",
        "  encoder_outputs, state_h1, state_c1 = encoder_lstm(encoder_inputs)\n",
        "  encoder_lstm2 = LSTM(numberOfLSTMunits,return_sequences=True, return_state=True,  name='encoder_lstm2')\n",
        "  _, state_h2, state_c2 = encoder_lstm2(encoder_outputs) \n",
        "\n",
        "  \n",
        "  # initial context vector is the states of the encoder\n",
        "  states = [state_h1, state_c1, state_h2, state_c2]\n",
        "\n",
        "\n",
        "  \n",
        "  # Set up the decoder layers\n",
        "  # Attention: decoder receives 1 token at a time &\n",
        "  # decoder outputs 1 token at a time \n",
        "  \n",
        "  decoder_inputs = Input(shape=(1, out_features),  name='decoder_inputs')\n",
        "  decoder_lstm = LSTM(numberOfLSTMunits, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "  \n",
        "  # Second LSTM\n",
        "  decoder_lstm2 = LSTM(numberOfLSTMunits, return_sequences=True, return_state=True, name='decoder_lstm2')\n",
        "\n",
        "\n",
        "  decoder_dense = Dense(out_features, activation='softmax',  name='decoder_dense')\n",
        "  # New input decoder\n",
        "  all_outputs = []\n",
        "  decoder_input_data = np.zeros((batch_size, 1, out_features))\n",
        "  decoder_input_data[:, 0, 0] = -1 \n",
        "  inputs = decoder_input_data\n",
        "  states1 = [state_h1, state_c1]\n",
        "  states2 = [state_h2, state_c2]\n",
        "  #print(inputs.shape)\n",
        "  for _ in range(n_timesteps_in):\n",
        "      # Run the decoder on one time step\n",
        "      #outputs, state_h, state_c = decoder_lstm(inputs, initial_state=states)\n",
        "      outputs, dh1, dc1 = decoder_lstm(inputs,initial_state= states1)\n",
        "      final, dh2, dc2 = decoder_lstm2(outputs, initial_state=states2)\n",
        "\n",
        "      outputs = decoder_dense(final)\n",
        "      # Store the current prediction (we will concatenate all predictions later)\n",
        "      all_outputs.append(outputs)\n",
        "      # Reinject the outputs as inputs for the next loop iteration\n",
        "      # as well as update the states\n",
        "      inputs = outputs\n",
        "      states1 = [state_h1, state_c1]\n",
        "      states2 = [state_h2, state_c2]\n",
        "  decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #encoder_model = Model(encoder_inputs, states)\n",
        "  #decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "  # Define and compile model \n",
        "  model = Model(encoder_inputs, decoder_outputs, name='model_encoder_decoder')\n",
        "  model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=[\"accuracy\", keras_metrics.precision(), keras_metrics.recall(), tf.keras.metrics.AUC()])\n",
        "  return model"
      ],
      "metadata": {
        "id": "3Qyj2ThT11wO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 SSummary of the model"
      ],
      "metadata": {
        "id": "Pk6GtzHm251Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjSB6QEHWv8U",
        "outputId": "4cf6c8b8-a71e-4515-8c13-a994ef1b87a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_encoder_decoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, 1, 113)]     0           []                               \n",
            "                                                                                                  \n",
            " encoder_lstm (LSTM)            [(None, 1, 256),     378880      ['encoder_inputs[0][0]']         \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)            [(192, 1, 256),      265216      ['encoder_lstm[0][1]',           \n",
            "                                 (None, 256),                     'encoder_lstm[0][2]']           \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " encoder_lstm2 (LSTM)           [(None, 1, 256),     525312      ['encoder_lstm[0][0]']           \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " decoder_lstm2 (LSTM)           [(192, 1, 256),      525312      ['decoder_lstm[0][0]',           \n",
            "                                 (None, 256),                     'encoder_lstm2[0][1]',          \n",
            "                                 (None, 256)]                     'encoder_lstm2[0][2]']          \n",
            "                                                                                                  \n",
            " decoder_dense (Dense)          (192, 1, 2)          514         ['decoder_lstm2[0][0]']          \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (192, 1, 2)          0           ['decoder_dense[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,695,234\n",
            "Trainable params: 1,695,234\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "batch_size = 192\n",
        "model_encoder_decoder=create_hard_coded_decoder_input_model(batch_size=batch_size)\n",
        "model_encoder_decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8 Training of the model"
      ],
      "metadata": {
        "id": "A74aSnsz27Lt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzuyR6NaXb2Q",
        "outputId": "01c7e341-6ed7-4fcf-f3a0-8b8bf94b0a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "657/657 [==============================] - 48s 73ms/step - loss: 0.0249 - accuracy: 0.9913 - precision: 0.9857 - recall: 0.9894 - auc: 0.9992\n",
            "--- 82.19271516799927 seconds ---\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "model_encoder_decoder.fit(x1, y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=1)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.9 Metrics for test data"
      ],
      "metadata": {
        "id": "gEj4vLaV3CDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_acc, test_precision, test_recall, test_auc = model_encoder_decoder.evaluate(xt1,yt, batch_size=batch_size, verbose=0)\n",
        "print(\"Test accuracy \", test_acc, \" Test precision \", test_precision, \" Test recall \", test_recall, \" Test AUC\", test_auc)"
      ],
      "metadata": {
        "id": "UwaR2-yJ3Fdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eadb9d9e-91e4-4b54-cadb-10c50a068dda"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n",
            "WARNING:tensorflow:`add_update` `inputs` kwarg has been deprecated. You no longer need to pass a value to `inputs` as it is being automatically inferred.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy  0.7928340435028076  Test precision  0.9722961187362671  Test recall  0.9897193908691406  Test AUC 0.8696174621582031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.10 Saving the model"
      ],
      "metadata": {
        "id": "jKn04KR8ugiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = model_encoder_decoder\n",
        "tf.saved_model.save(model,'NIDS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf2Po2xAuvtO",
        "outputId": "966b1026-eedb-47f0-dc0e-05c29224577d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras_metrics.metrics.precision object at 0x7fa81cf83f10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras_metrics.metrics.recall object at 0x7fa81a1a92d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras_metrics.metrics.true_positive object at 0x7fa81a1a9fd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras_metrics.metrics.false_positive object at 0x7fa81a1a9d50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras_metrics.metrics.true_positive object at 0x7fa81cf837d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras_metrics.metrics.false_negative object at 0x7fa81cfd5490>, because it is not built.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FIN DU CODE"
      ],
      "metadata": {
        "id": "rfjDoH0y3Kae"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}